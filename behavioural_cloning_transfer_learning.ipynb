{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "correction = 0.3\n",
    "\n",
    "lines = []\n",
    "\n",
    "with open('../cardata/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "\n",
    "class Augmentation(Enum):\n",
    "    Original = 0\n",
    "    Left = 1\n",
    "    Right = 2\n",
    "    Reverse_Original = 3\n",
    "    Reverse_Left = 4\n",
    "    Reverse_Right = 5\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def load_image(source_path):\n",
    "    #filename = source_path.split('/')[-1]\n",
    "    #current_path = '../data/IMG/' + filename \n",
    "    return cv2.imread(source_path)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    augmented_samples = list(itertools.product(samples, [aug for aug in Augmentation]))\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        sklearn.utils.shuffle(augmented_samples)\n",
    "\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = augmented_samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "\n",
    "                steering = float(batch_sample[0][3])\n",
    "                if batch_sample[1].value % 3 == 0:\n",
    "                    image = load_image(batch_sample[0][0])\n",
    "                if batch_sample[1].value % 3 == 1:\n",
    "                    image = load_image(batch_sample[0][1])\n",
    "                    steering = steering + correction\n",
    "                if batch_sample[1].value % 3 == 2:\n",
    "                    image = load_image(batch_sample[0][2])\n",
    "                    steering = steering - correction\n",
    "                if batch_sample[1].value > 2:\n",
    "                    image = np.fliplr(image)\n",
    "                    steering = steering * -1.0\n",
    "                \n",
    "                images.append(image)\n",
    "                angles.append(steering)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history_object):\n",
    "    ### print the keys contained in the history object\n",
    "    print(history_object.history.keys())\n",
    "\n",
    "    ### plot the training and validation loss for each epoch\n",
    "    plt.plot(history_object.history['loss'])\n",
    "    plt.plot(history_object.history['val_loss'])\n",
    "    plt.title('model mean squared error loss')\n",
    "    plt.ylabel('mean squared error loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=5, validation_data=<generator..., verbose=1, steps_per_epoch=9312, validation_steps=2334)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 544/9312 [>.............................] - ETA: 12:29:58 - loss: 0.0758"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-7267e8c87414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAugmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# this could also be the output a different Keras model or layer\n",
    "input_tensor = Input(shape=(160, 320, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "base_model = DenseNet121(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "prediction = Dense(1)(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "train_generator = generator(traLosin_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "\n",
    "history_object = model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=len(train_samples)*len(Augmentation), \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps = len(validation_samples)*len(Augmentation), \n",
    "    epochs=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "plot_history(history_object)\n",
    "\n",
    "model.save('model_tf.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = generator(traLosin_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "\n",
    "history_object = model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=len(train_samples)*len(Augmentation), \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps = len(validation_samples)*len(Augmentation), \n",
    "    epochs=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "plot_history(history_object)\n",
    "\n",
    "model.save('model_tf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_5\n",
      "1 conv2d_377\n",
      "2 batch_normalization_377\n",
      "3 activation_377\n",
      "4 conv2d_378\n",
      "5 batch_normalization_378\n",
      "6 activation_378\n",
      "7 conv2d_379\n",
      "8 batch_normalization_379\n",
      "9 activation_379\n",
      "10 max_pooling2d_17\n",
      "11 conv2d_380\n",
      "12 batch_normalization_380\n",
      "13 activation_380\n",
      "14 conv2d_381\n",
      "15 batch_normalization_381\n",
      "16 activation_381\n",
      "17 max_pooling2d_18\n",
      "18 conv2d_385\n",
      "19 batch_normalization_385\n",
      "20 activation_385\n",
      "21 conv2d_383\n",
      "22 conv2d_386\n",
      "23 batch_normalization_383\n",
      "24 batch_normalization_386\n",
      "25 activation_383\n",
      "26 activation_386\n",
      "27 average_pooling2d_37\n",
      "28 conv2d_382\n",
      "29 conv2d_384\n",
      "30 conv2d_387\n",
      "31 conv2d_388\n",
      "32 batch_normalization_382\n",
      "33 batch_normalization_384\n",
      "34 batch_normalization_387\n",
      "35 batch_normalization_388\n",
      "36 activation_382\n",
      "37 activation_384\n",
      "38 activation_387\n",
      "39 activation_388\n",
      "40 mixed0\n",
      "41 conv2d_392\n",
      "42 batch_normalization_392\n",
      "43 activation_392\n",
      "44 conv2d_390\n",
      "45 conv2d_393\n",
      "46 batch_normalization_390\n",
      "47 batch_normalization_393\n",
      "48 activation_390\n",
      "49 activation_393\n",
      "50 average_pooling2d_38\n",
      "51 conv2d_389\n",
      "52 conv2d_391\n",
      "53 conv2d_394\n",
      "54 conv2d_395\n",
      "55 batch_normalization_389\n",
      "56 batch_normalization_391\n",
      "57 batch_normalization_394\n",
      "58 batch_normalization_395\n",
      "59 activation_389\n",
      "60 activation_391\n",
      "61 activation_394\n",
      "62 activation_395\n",
      "63 mixed1\n",
      "64 conv2d_399\n",
      "65 batch_normalization_399\n",
      "66 activation_399\n",
      "67 conv2d_397\n",
      "68 conv2d_400\n",
      "69 batch_normalization_397\n",
      "70 batch_normalization_400\n",
      "71 activation_397\n",
      "72 activation_400\n",
      "73 average_pooling2d_39\n",
      "74 conv2d_396\n",
      "75 conv2d_398\n",
      "76 conv2d_401\n",
      "77 conv2d_402\n",
      "78 batch_normalization_396\n",
      "79 batch_normalization_398\n",
      "80 batch_normalization_401\n",
      "81 batch_normalization_402\n",
      "82 activation_396\n",
      "83 activation_398\n",
      "84 activation_401\n",
      "85 activation_402\n",
      "86 mixed2\n",
      "87 conv2d_404\n",
      "88 batch_normalization_404\n",
      "89 activation_404\n",
      "90 conv2d_405\n",
      "91 batch_normalization_405\n",
      "92 activation_405\n",
      "93 conv2d_403\n",
      "94 conv2d_406\n",
      "95 batch_normalization_403\n",
      "96 batch_normalization_406\n",
      "97 activation_403\n",
      "98 activation_406\n",
      "99 max_pooling2d_19\n",
      "100 mixed3\n",
      "101 conv2d_411\n",
      "102 batch_normalization_411\n",
      "103 activation_411\n",
      "104 conv2d_412\n",
      "105 batch_normalization_412\n",
      "106 activation_412\n",
      "107 conv2d_408\n",
      "108 conv2d_413\n",
      "109 batch_normalization_408\n",
      "110 batch_normalization_413\n",
      "111 activation_408\n",
      "112 activation_413\n",
      "113 conv2d_409\n",
      "114 conv2d_414\n",
      "115 batch_normalization_409\n",
      "116 batch_normalization_414\n",
      "117 activation_409\n",
      "118 activation_414\n",
      "119 average_pooling2d_40\n",
      "120 conv2d_407\n",
      "121 conv2d_410\n",
      "122 conv2d_415\n",
      "123 conv2d_416\n",
      "124 batch_normalization_407\n",
      "125 batch_normalization_410\n",
      "126 batch_normalization_415\n",
      "127 batch_normalization_416\n",
      "128 activation_407\n",
      "129 activation_410\n",
      "130 activation_415\n",
      "131 activation_416\n",
      "132 mixed4\n",
      "133 conv2d_421\n",
      "134 batch_normalization_421\n",
      "135 activation_421\n",
      "136 conv2d_422\n",
      "137 batch_normalization_422\n",
      "138 activation_422\n",
      "139 conv2d_418\n",
      "140 conv2d_423\n",
      "141 batch_normalization_418\n",
      "142 batch_normalization_423\n",
      "143 activation_418\n",
      "144 activation_423\n",
      "145 conv2d_419\n",
      "146 conv2d_424\n",
      "147 batch_normalization_419\n",
      "148 batch_normalization_424\n",
      "149 activation_419\n",
      "150 activation_424\n",
      "151 average_pooling2d_41\n",
      "152 conv2d_417\n",
      "153 conv2d_420\n",
      "154 conv2d_425\n",
      "155 conv2d_426\n",
      "156 batch_normalization_417\n",
      "157 batch_normalization_420\n",
      "158 batch_normalization_425\n",
      "159 batch_normalization_426\n",
      "160 activation_417\n",
      "161 activation_420\n",
      "162 activation_425\n",
      "163 activation_426\n",
      "164 mixed5\n",
      "165 conv2d_431\n",
      "166 batch_normalization_431\n",
      "167 activation_431\n",
      "168 conv2d_432\n",
      "169 batch_normalization_432\n",
      "170 activation_432\n",
      "171 conv2d_428\n",
      "172 conv2d_433\n",
      "173 batch_normalization_428\n",
      "174 batch_normalization_433\n",
      "175 activation_428\n",
      "176 activation_433\n",
      "177 conv2d_429\n",
      "178 conv2d_434\n",
      "179 batch_normalization_429\n",
      "180 batch_normalization_434\n",
      "181 activation_429\n",
      "182 activation_434\n",
      "183 average_pooling2d_42\n",
      "184 conv2d_427\n",
      "185 conv2d_430\n",
      "186 conv2d_435\n",
      "187 conv2d_436\n",
      "188 batch_normalization_427\n",
      "189 batch_normalization_430\n",
      "190 batch_normalization_435\n",
      "191 batch_normalization_436\n",
      "192 activation_427\n",
      "193 activation_430\n",
      "194 activation_435\n",
      "195 activation_436\n",
      "196 mixed6\n",
      "197 conv2d_441\n",
      "198 batch_normalization_441\n",
      "199 activation_441\n",
      "200 conv2d_442\n",
      "201 batch_normalization_442\n",
      "202 activation_442\n",
      "203 conv2d_438\n",
      "204 conv2d_443\n",
      "205 batch_normalization_438\n",
      "206 batch_normalization_443\n",
      "207 activation_438\n",
      "208 activation_443\n",
      "209 conv2d_439\n",
      "210 conv2d_444\n",
      "211 batch_normalization_439\n",
      "212 batch_normalization_444\n",
      "213 activation_439\n",
      "214 activation_444\n",
      "215 average_pooling2d_43\n",
      "216 conv2d_437\n",
      "217 conv2d_440\n",
      "218 conv2d_445\n",
      "219 conv2d_446\n",
      "220 batch_normalization_437\n",
      "221 batch_normalization_440\n",
      "222 batch_normalization_445\n",
      "223 batch_normalization_446\n",
      "224 activation_437\n",
      "225 activation_440\n",
      "226 activation_445\n",
      "227 activation_446\n",
      "228 mixed7\n",
      "229 conv2d_449\n",
      "230 batch_normalization_449\n",
      "231 activation_449\n",
      "232 conv2d_450\n",
      "233 batch_normalization_450\n",
      "234 activation_450\n",
      "235 conv2d_447\n",
      "236 conv2d_451\n",
      "237 batch_normalization_447\n",
      "238 batch_normalization_451\n",
      "239 activation_447\n",
      "240 activation_451\n",
      "241 conv2d_448\n",
      "242 conv2d_452\n",
      "243 batch_normalization_448\n",
      "244 batch_normalization_452\n",
      "245 activation_448\n",
      "246 activation_452\n",
      "247 max_pooling2d_20\n",
      "248 mixed8\n",
      "249 conv2d_457\n",
      "250 batch_normalization_457\n",
      "251 activation_457\n",
      "252 conv2d_454\n",
      "253 conv2d_458\n",
      "254 batch_normalization_454\n",
      "255 batch_normalization_458\n",
      "256 activation_454\n",
      "257 activation_458\n",
      "258 conv2d_455\n",
      "259 conv2d_456\n",
      "260 conv2d_459\n",
      "261 conv2d_460\n",
      "262 average_pooling2d_44\n",
      "263 conv2d_453\n",
      "264 batch_normalization_455\n",
      "265 batch_normalization_456\n",
      "266 batch_normalization_459\n",
      "267 batch_normalization_460\n",
      "268 conv2d_461\n",
      "269 batch_normalization_453\n",
      "270 activation_455\n",
      "271 activation_456\n",
      "272 activation_459\n",
      "273 activation_460\n",
      "274 batch_normalization_461\n",
      "275 activation_453\n",
      "276 mixed9_0\n",
      "277 concatenate_9\n",
      "278 activation_461\n",
      "279 mixed9\n",
      "280 conv2d_466\n",
      "281 batch_normalization_466\n",
      "282 activation_466\n",
      "283 conv2d_463\n",
      "284 conv2d_467\n",
      "285 batch_normalization_463\n",
      "286 batch_normalization_467\n",
      "287 activation_463\n",
      "288 activation_467\n",
      "289 conv2d_464\n",
      "290 conv2d_465\n",
      "291 conv2d_468\n",
      "292 conv2d_469\n",
      "293 average_pooling2d_45\n",
      "294 conv2d_462\n",
      "295 batch_normalization_464\n",
      "296 batch_normalization_465\n",
      "297 batch_normalization_468\n",
      "298 batch_normalization_469\n",
      "299 conv2d_470\n",
      "300 batch_normalization_462\n",
      "301 activation_464\n",
      "302 activation_465\n",
      "303 activation_468\n",
      "304 activation_469\n",
      "305 batch_normalization_470\n",
      "306 activation_462\n",
      "307 mixed9_1\n",
      "308 concatenate_10\n",
      "309 activation_470\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
